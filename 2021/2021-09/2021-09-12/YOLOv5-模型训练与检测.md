# YOLOv5-æ¨¡å‹è®­ç»ƒä¸æ£€æµ‹

  - [ä¸‹è½½ OIDv4_ToolKit æ•°æ®é›†](#%E4%B8%8B%E8%BD%BD-oidv4_toolkit-%E6%95%B0%E6%8D%AE%E9%9B%86)
  - [ä¸‹è½½ Apple å’Œ Orange çš„æ•°æ®é›†](#%E4%B8%8B%E8%BD%BD-apple-%E5%92%8C-orange-%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86)
  - [è½¬æ¢æ ‡ç­¾æ ¼å¼](#%E8%BD%AC%E6%8D%A2%E6%A0%87%E7%AD%BE%E6%A0%BC%E5%BC%8F)
  - [ç¼–å†™ dataset.yaml æ–‡ä»¶](#%E7%BC%96%E5%86%99-datasetyaml-%E6%96%87%E4%BB%B6)
  - [ç¼–å†™ yolov5s.yaml æ–‡ä»¶](#%E7%BC%96%E5%86%99-yolov5syaml-%E6%96%87%E4%BB%B6)
  - [å¼€å§‹è®­ç»ƒ](#%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83)
  - [æŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹](#%E6%9F%A5%E7%9C%8B%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B)
  - [è¿›è¡Œæ£€æµ‹](#%E8%BF%9B%E8%A1%8C%E6%A3%80%E6%B5%8B)
  - [æ¨¡å‹è½¬æ¢](#%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2)

## ä¸‹è½½ OIDv4_ToolKit æ•°æ®é›†
```bash
git clone https://github.com/EscVM/OIDv4_ToolKit.git
# å®‰è£…ä¾èµ–
pip install -r .\requirements.txt
```

## ä¸‹è½½ Apple å’Œ Orange çš„æ•°æ®é›†
```bash
python .\main.py downloader --classes Apple Orange --type_csv all
```

## è½¬æ¢æ ‡ç­¾æ ¼å¼
ç¼–å†™ python è„šæœ¬å¦‚ä¸‹ï¼š
```python
from genericpath import isfile
import  os
import  cv2 as cv

root_dir = "E:\\code\\github\\OIDv4_ToolKit\\OID\Dataset"
valid_label_dir = "E:\\code\\python\\openvino_utils\\data\\labels\\valid"

def read_annotation(data_type = "train", class_type = "Apple"):
    current_dir = os.path.join(root_dir, data_type, class_type)
    print(current_dir)
    files = os.listdir(current_dir)
    for f in files:
        if (os.path.isfile(os.path.join(current_dir, f))):
            image = cv.imread(os.path.join(current_dir, f))
            label_file = os.path.join(current_dir, "label", f.replace(".jpg", ".txt"))
            yolo_label = f.replace(".jpg", ".txt")
            data_label_text_f = os.path.join(valid_label_dir, yolo_label)
            file_write_obj = open(data_label_text_f, 'w')

            with open(label_file) as f:
                boxes = [line.strip() for line in f.readlines()]

            class_index = -1
            for box in boxes:
                anno_info = box.split(" ")
                print("class name: ", anno_info[0])
                x1 = float(anno_info[1])
                y1 = float(anno_info[2])
                x2 = float(anno_info[3])
                y2 = float(anno_info[4])

                if anno_info[0] == "Apple":
                    class_index = 0
                else:
                    class_index = 1
                
                h, w, c = image.shape
                cx = (x1 + x2) / (2 * w)
                cy = (y1 + y2) / (2 * h)
                sw = (x2 - x1) / w
                sh = (y2 - y1) / h
                file_write_obj.write("%d %f %f %f %f\n" % (class_index, cx, cy, sw, sh))

            file_write_obj.close()

if __name__ == "__main__":
    read_annotation(data_type="validation", class_type="Orange")
```

è½¬æ¢å®Œæ¯•åï¼Œå°†æ ‡ç­¾å’Œå›¾ç‰‡æ•°æ®æ”¾åœ¨ yolov5 ç›®å½•ä¸‹çš„ fruit_training ä¸‹çš„ data ç›®å½•ä¸‹ï¼Œæ²¡æœ‰ç›®å½•å°±åˆ›å»º

## ç¼–å†™ dataset.yaml æ–‡ä»¶
å‚è€ƒ `yolov5\data\VOC.yaml` æ–‡ä»¶ï¼Œåœ¨ `yolov5\fruit_training\` ç›®å½•ä¸‹åˆ›å»º `dataset.yaml` æ–‡ä»¶ï¼Œç¼–å†™å†…å®¹å¦‚ä¸‹ï¼š
```yaml
train: fruit_training/data/images/train/
val: fruit_training/data/images/valid

nc: 2

names: ['Apple', 'Orange']
```

## ç¼–å†™ yolov5s.yaml æ–‡ä»¶
å‚è€ƒ `yolov5\models\yolov5s.yaml` æ–‡ä»¶ï¼Œæ‹·è´åˆ° `yolov5\fruit_training\` ç›®å½•ä¸‹ï¼Œä¿®æ”¹ nc ä¸º 2ã€‚æ–‡ä»¶å†…å¦‚ä¸‹ï¼š
```yaml
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 2  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Focus, [64, 3]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 9, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 1, SPP, [1024, [5, 9, 13]]],
   [-1, 3, C3, [1024, False]],  # 9
  ]

# YOLOv5 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
```

## å¼€å§‹è®­ç»ƒ
è¿è¡Œå‘½ä»¤ï¼š`python .\train.py --data fruit_training/dataset.yaml --cfg fruit_training/yolov5s.yaml --weights yolov5s.pt --batch-size 1 --epochs 2`

## æŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹
è¿è¡Œå‘½ä»¤ï¼š`tensorboard --logdir=E:\code\python\yolov5\runs\train\exp`

## è¿›è¡Œæ£€æµ‹
ä¸‹è½½å‡ ä¸ªè‹¹æœå’Œæ©˜å­çš„å›¾ç‰‡æ”¾åˆ° fruit_training ç›®å½•ä¸‹ï¼Œè¿è¡Œæ£€æµ‹å‘½ä»¤ï¼š
```bash
python .\detect.py --source .\fruit_training\apple.jpeg --weights .\fruit_training\best.pt --conf 0.25
```

å“¦å¯¹ï¼Œè¿˜è¦æŠŠè®­ç»ƒå¥½çš„ `best.pt` æ¨¡å‹ä¹Ÿæ”¾åˆ° fruit_training ç›®å½•ä¸‹

## æ¨¡å‹è½¬æ¢
çœ‹ `requirements.txt` æ–‡ä»¶é‡Œæ˜¯å¦æœ‰å®‰è£… `coremltools` å’Œ `onnx` è¿™ä¸¤ä¸ªç¬¬ä¸‰æ–¹åº“ï¼Œæ²¡æœ‰çš„è¯å°±å®‰è£…ï¼š
```bash
pip install coremltools>=4.1 -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install onnx>=1.9.0 -i https://pypi.tuna.tsinghua.edu.cn/simple
```

å®‰è£…å®Œæˆåï¼Œè¿è¡Œä¸‹é¢å‘½ä»¤è¿›è¡Œæ¨¡å‹è½¬æ¢ï¼š
```bash
python .\export.py --weights .\fruit_training\best.pt --img 640 --batch 1
```
